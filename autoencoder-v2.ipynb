{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder v2\n",
    "## Details:\n",
    "1. 6 layers each in encoder and decoder (3 Conv3d, 3 MaxPooling3D)\n",
    "2. Dataset - 1000 STL files\n",
    "3. Train - 800 models\n",
    "4. Test - 200 models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, Flatten, Reshape\n",
    "from keras.models import Model\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyntcloud import PyntCloud\n",
    "import open3d as o3d\n",
    "from ConversionUtils import ConversionUtils\n",
    "from Visualization import Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting point cloud to binary voxel arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"abc-dataset-ply/\"\n",
    "files = sorted([filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))])[:1000]\n",
    "print(len(files))\n",
    "dataset = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in files:\n",
    "    path = os.path.join(directory, i)\n",
    "    binvox = ConversionUtils.convert_to_binvox(path)\n",
    "    dataset.append(binvox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)\n",
    "num = int(1000*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset into numpy arrays\n",
    "# Here we are using 800 models in train dataset, and 200 in test dataset\n",
    "# Split your dataset into train and test datasets\n",
    "train_dataset = dataset[:num]  # Adjust the number as needed\n",
    "test_dataset = dataset[num:]   # The remaining data for testing\n",
    "# Define the input shape\n",
    "input_shape = (64, 64, 64, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Input(shape=input_shape)\n",
    "x = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(input_data)\n",
    "x = MaxPooling3D((2, 2, 2), padding='same')(x)\n",
    "x = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling3D((2, 2, 2), padding='same')(x)\n",
    "x = Conv3D(8, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "# x = MaxPooling3D((2, 2, 2), padding='same')(x)\n",
    "# x = Conv3D(4, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling3D((2, 2, 2), padding='same')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = Conv3D(4, (3, 3, 3), activation='relu', padding='same')(encoded)\n",
    "# x = UpSampling3D((2, 2, 2))(x)\n",
    "x = Conv3D(8, (3, 3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling3D((2, 2, 2))(x)\n",
    "x = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling3D((2, 2, 2))(x)\n",
    "x = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling3D((2, 2, 2))(x)\n",
    "decoded = Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training autoencoder, prediction done on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_data, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "autoencoder.fit(train_dataset, train_dataset, epochs=40, batch_size=10, validation_data=(test_dataset, test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data = autoencoder.predict(test_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample reconstruction from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 2\n",
    "\n",
    "original_sample = test_dataset[index]\n",
    "\n",
    "reconstructed_sample = reconstructed_data[index].reshape(64, 64, 64)\n",
    "threshold = 0.1\n",
    "reconstructed_sample = (reconstructed_sample > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualization.open3d_visualize_original(original_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualization.open3d_visualize_reconstructed(reconstructed_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
