{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "\n",
    "# Function to read obj file and compute the number of vertices\n",
    "\n",
    "def read_obj_file(file_path):\n",
    "    vertices = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('v '):\n",
    "                components = line.split()[1:]\n",
    "                vertex = [float(comp) for comp in components]\n",
    "                vertices.append(vertex)\n",
    "\n",
    "    return np.array(vertices)\n",
    "\n",
    "# Sample\n",
    "sample_cad_model = read_obj_file(\"/home/hrishi/Programming/Python/CAD-DR/abc-dataset/00030037_0ef34aa1b15748a5b4ad7c0e_trimesh_027.obj\")\n",
    "print(sample_cad_model)\n",
    "print(sample_cad_model.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory_path = '/home/hrishi/Programming/Python/CAD-DR/abc-dataset/'\n",
    "file_paths = [os.path.join(directory_path, filename) for filename in os.listdir(directory_path) if os.path.isfile(os.path.join(directory_path, filename))]\n",
    "print(len(file_paths))\n",
    "print(file_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = []\n",
    "for i in file_paths:\n",
    "    data = read_obj_file(str(i))\n",
    "    data = pd.DataFrame(data)\n",
    "    dataset.append(data)\n",
    "\n",
    "print(dataset)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the number of vertices of each model in the dataset\n",
    "max_vertices = 0\n",
    "min_vertices = 1000000\n",
    "for filename in os.listdir(\"abc-dataset\"):\n",
    "    vertices = len(read_obj_file(\"abc-dataset/\" + str(filename)))\n",
    "    # print(vertices) - can be used if we wish to see number of vertices of each model\n",
    "    if (vertices > max_vertices):\n",
    "        max_vertices = vertices\n",
    "    if (vertices < min_vertices):\n",
    "        min_vertices = vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of vertices\n",
    "print(max_vertices)\n",
    "print(min_vertices)\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "if tf.test.is_gpu_available():\n",
    "    print(\"GPU is available and being used by TensorFlow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "dataframes = dataset\n",
    "data = np.vstack([df.values for df in dataframes])\n",
    "\n",
    "desired_dimensions = 1900\n",
    "\n",
    "num_encoding_layers = 10\n",
    "num_decoding_layers = 10\n",
    "\n",
    "input_layer = Input(shape=(data.shape[1],))\n",
    "encoded = input_layer\n",
    "\n",
    "for _ in range(num_encoding_layers):\n",
    "    encoded = Dense(512, activation='relu')(encoded)\n",
    "\n",
    "encoded = Dense(desired_dimensions, activation='relu')(encoded)\n",
    "decoded = encoded\n",
    "for _ in range(num_decoding_layers):\n",
    "    decoded = Dense(512, activation='relu')(decoded)\n",
    "\n",
    "decoded = Dense(data.shape[1], activation='linear')(decoded)\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "encoder = Model(input_layer, encoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "reduced_dataframes = []\n",
    "\n",
    "for epoch in range(4):\n",
    "    autoencoder.fit(data, data, batch_size=60)\n",
    "\n",
    "    epoch_reduced_dataframes = []\n",
    "\n",
    "    for i, dataframe in enumerate(dataframes):\n",
    "        sample_data = dataframe.values\n",
    "        latent_representation = encoder.predict(sample_data)\n",
    "        reconstructed_data = autoencoder.predict(sample_data)\n",
    "\n",
    "        epoch_reduced_dataframes.append(pd.DataFrame(latent_representation))\n",
    "\n",
    "    reduced_dataframes.append(epoch_reduced_dataframes)\n",
    "\n",
    "\n",
    "epoch_to_print = 0\n",
    "for i, reduced_dataframe in enumerate(reduced_dataframes[epoch_to_print]):\n",
    "    print(\n",
    "        f'Reduced Dimensionality DataFrame (Epoch {epoch_to_print+1}, DataFrame {i+1}):')\n",
    "    print(reduced_dataframe)\n",
    "\n",
    "autoencoder.save_weights('autoencoder_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the autoencoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.regularizers import l2\n",
    "\n",
    "dataframes = dataset\n",
    "data = np.vstack([df.values for df in dataframes])\n",
    "\n",
    "desired_dimensions = 1900\n",
    "\n",
    "num_encoding_layers = 10\n",
    "num_decoding_layers = 10\n",
    "\n",
    "input_layer = Input(shape=(data.shape[1],))\n",
    "encoded = input_layer\n",
    "\n",
    "for _ in range(num_encoding_layers):\n",
    "    encoded = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(encoded)\n",
    "\n",
    "encoded = Dense(desired_dimensions, activation='relu')(encoded)\n",
    "decoded = encoded\n",
    "\n",
    "for _ in range(num_decoding_layers):\n",
    "    decoded = Dense(1024, activation='relu', kernel_regularizer=l2(0.01))(decoded)\n",
    "\n",
    "decoded = Dense(data.shape[1], activation='sigmoid')(decoded)\n",
    "autoencoder = Model(input_layer, decoded)\n",
    "encoder = Model(input_layer, encoded)\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "autoencoder.compile(optimizer=optimizer, loss='mse', batch_size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the ae on other data\n",
    "\n",
    "reduced_dimensionality_representations = []\n",
    "for dataframe in dataframes:\n",
    "  sample_data = dataframe.values\n",
    "  latent_representation = encoder.predict(sample_data)\n",
    "  reduced_dimensionality_representations.append(latent_representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
