{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "\n",
    "torch.set_default_device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an Autoencoder class\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_dim),\n",
    "            nn.Sigmoid()  # Sigmoid to constrain output between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_obj(file_path):\n",
    "    vertices = []\n",
    "\n",
    "    try:\n",
    "        with open(file_path, 'r') as obj_file:\n",
    "            for line in obj_file:\n",
    "                tokens = line.strip().split()\n",
    "                if len(tokens) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Process vertex data (assuming \"v\" lines in the OBJ file)\n",
    "                if tokens[0] == 'v':\n",
    "                    if len(tokens) >= 4:\n",
    "                        # Extract the x, y, z coordinates\n",
    "                        x = float(tokens[1])\n",
    "                        y = float(tokens[2])\n",
    "                        z = float(tokens[3])\n",
    "                        vertices.append([x, y, z])\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "        return None\n",
    "\n",
    "    if len(vertices) == 0:\n",
    "        print(\"No vertex data found in the OBJ file.\")\n",
    "        return None\n",
    "\n",
    "    # Convert the list of vertices to a NumPy array\n",
    "    vertices = np.array(vertices, dtype=np.float32)\n",
    "\n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_autoencoder(model, data, num_epochs=50, learning_rate=0.001):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs in data:\n",
    "            optimizer.zero_grad()\n",
    "            inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, inputs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess your OBJ data\n",
    "obj_data = load_and_preprocess_step(\"abc-dataset-obj/00030048_0ef34aa1b15748a5b4ad7c0e_trimesh_038.obj\").T\n",
    "\n",
    "# Define your input dimension and latent dimension\n",
    "input_dim = len(obj_data[0])  # Modify based on your data structure\n",
    "print(input_dim)\n",
    "latent_dim = input_dim  # Adjust as needed\n",
    "\n",
    "# Create and train the autoencoder\n",
    "autoencoder = Autoencoder(input_dim, latent_dim)\n",
    "\n",
    "train_autoencoder(autoencoder, obj_data)\n",
    "\n",
    "# Reduce the number of meshes by encoding and decoding\n",
    "def reduce_meshes(autoencoder, data):\n",
    "    reduced_meshes = []\n",
    "    for mesh in data:\n",
    "        mesh = torch.tensor(mesh, dtype=torch.float32)\n",
    "        encoded_mesh = autoencoder.encoder(mesh)\n",
    "        decoded_mesh = autoencoder.decoder(encoded_mesh)\n",
    "        reduced_meshes.append(decoded_mesh.detach().cpu().numpy())\n",
    "    return reduced_meshes\n",
    "\n",
    "# Use the trained autoencoder to reduce meshes\n",
    "reduced_meshes = reduce_meshes(autoencoder, obj_data)\n",
    "\n",
    "# Save or visualize the reduced meshes as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# ... (Previous code for Autoencoder, training, and mesh reduction)\n",
    "\n",
    "# Function to visualize a 3D mesh\n",
    "def visualize_mesh(mesh, title=\"Reduced Mesh\"):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    \n",
    "    # Extract x, y, z coordinates from the mesh\n",
    "    x = mesh.loc[0]\n",
    "    y = mesh.loc[1]\n",
    "    z = mesh.loc[2]\n",
    "\n",
    "    print(x)\n",
    "    print(y)\n",
    "    print(z)\n",
    "    \n",
    "    ax.scatter(x, y, z)\n",
    "    ax.set_title(title)\n",
    "    plt.show()\n",
    "\n",
    "obj_data = pd.DataFrame(obj_data)\n",
    "reduced_meshes = pd.DataFrame(reduced_meshes)\n",
    "\n",
    "visualize_mesh(obj_data, title=\"Original Mesh\")\n",
    "visualize_mesh(reduced_meshes, title=\"Reduced Mesh\")\n",
    "\n",
    "# Reconstruct the mesh from the reduced version\n",
    "reconstructed_mesh = autoencoder.decoder(torch.tensor(reduced_meshes.values, dtype=torch.float32)).detach().cpu().numpy()\n",
    "reconstructed_mesh_df = pd.DataFrame(reconstructed_mesh)  # Convert the reconstructed mesh to a DataFrame\n",
    "visualize_mesh(reconstructed_mesh_df, title=\"Reconstructed Mesh\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
