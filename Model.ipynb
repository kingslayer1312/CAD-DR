{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAD-DR: CAD Dimensionality Reduction\n",
    "\n",
    "A deep convolutional autoencoder for dimensionality reduction of 3D CAD models\n",
    "\n",
    "### Information\n",
    "1. Ten-layer architecture (5 in encoder + 5 in decoder)\n",
    "2. Dataset - 1000 STL files\n",
    "3. Train - 800 models\n",
    "4. Test - 200 models\n",
    "5. Epochs - 50\n",
    "6. Point cloud density - 20k points\n",
    "\n",
    "### Metrics\n",
    "1. loss: 0.0180\n",
    "2. accuracy: 0.9920 (99.20%)\n",
    "3. val_loss: 0.0120\n",
    "4. val_accuracy: 0.9948 (99.48%)\n",
    "\n",
    "### Encoder architecture\n",
    "- Conv3D(32, (3, 3, 3), activation='selu', padding='same')\n",
    "- AveragePooling3D((2, 2, 2), padding='same')\n",
    "- Conv3D(16, (3, 3, 3), activation='selu', padding='same')\n",
    "- AveragePooling3D((2, 2, 2), padding='same')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell in case you haven't installed the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas pyntcloud open3d\n",
    "!pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing all necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv3D, UpSampling3D, AveragePooling3D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pyntcloud import PyntCloud\n",
    "import open3d as o3d\n",
    "from ConversionUtils import ConversionUtils\n",
    "from Visualization import Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting STL to point cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute the following cell if you wish to delete all existing point cloud files in abc-dataset-ply/ directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"abc-dataset-ply/\"\n",
    "files = os.listdir(folder_path)\n",
    "\n",
    "for file in files:\n",
    "    file_path = os.path.join(folder_path, file)\n",
    "    if os.path.isfile(file_path):\n",
    "        try:\n",
    "            os.remove(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting {file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Only execute the next cell if the point cloud files do not exist in abc-dataset-ply/ directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = sorted(ConversionUtils.list_files_in_directory(\"abc-dataset-stl/\"))[302]\n",
    "for i in files:\n",
    "    path = \"abc-dataset-stl/\" + i\n",
    "    ConversionUtils.stl_to_ply(path, 20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting point cloud to binary voxel arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"abc-dataset-ply/\"\n",
    "\n",
    "files = sorted([filename for filename in os.listdir(directory) if os.path.isfile(os.path.join(directory, filename))])\n",
    "dataset = []\n",
    "\n",
    "for i in files:\n",
    "    path = os.path.join(directory, i)\n",
    "    binvox = ConversionUtils.convert_to_binvox(path, 64)\n",
    "    dataset.append(binvox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting dataset for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)\n",
    "\n",
    "train_dataset_length = int(0.8 * len(dataset))\n",
    "test_set_length = int(0.2 * len(dataset))\n",
    "\n",
    "train_dataset = dataset[:train_dataset_length]  \n",
    "test_dataset = dataset[train_dataset_length:]   \n",
    "print(len(train_dataset), len(test_dataset))\n",
    "\n",
    "input_shape = (64, 64, 64, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = Input(shape=input_shape)\n",
    "x = Conv3D(32, (3, 3, 3), activation='selu', padding='same')(input_data)\n",
    "x = AveragePooling3D((2, 2, 2), padding='same')(x)\n",
    "x = Conv3D(16, (3, 3, 3), activation='selu', padding='same')(x)\n",
    "encoded = AveragePooling3D((2, 2, 2), padding='same')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Conv3D(16, (3, 3, 3), activation='selu', padding='same')(encoded)\n",
    "x = UpSampling3D((2, 2, 2))(x)\n",
    "x = Conv3D(32, (3, 3, 3), activation='selu', padding='same')(x)\n",
    "x = UpSampling3D((2, 2, 2))(x)\n",
    "decoded = Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    min_delta=0.0001,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode=\"min\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    "    start_from_epoch=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = 'checkpoints/checkpoint.weights.h5'\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training autoencoder, prediction done on test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Model(input_data, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "autoencoder.fit(train_dataset, train_dataset, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(test_dataset, test_dataset), callbacks=[early_stopping, model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_data = autoencoder.predict(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Model(autoencoder.input, autoencoder.layers[5].output)\n",
    "encoded_data = encoder.predict(test_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving autoencoder and encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save(\"saved-models/autoencoder.keras\")\n",
    "encoder.save(\"saved-models/encoder.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of input data: \", test_dataset[0].shape)\n",
    "print(\"Shape of encoded data: \", encoded_data[0].shape)\n",
    "print(\"Shape of reconstructed data: \", reconstructed_data[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample reconstruction from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "index = 55 # change this value to visualize different models and their reconstructions\n",
    "\n",
    "original_sample = test_dataset[index]\n",
    "\n",
    "reconstructed_sample = reconstructed_data[index].reshape(64, 64, 64)\n",
    "threshold = 0.35\n",
    "reconstructed_sample = (reconstructed_sample > threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualization.matplotlib_visualize_original(original_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualization.matplotlib_visualize_reconstructed(reconstructed_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualization.open3d_visualize_original(original_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Visualization.open3d_visualize_reconstructed(reconstructed_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing encoded data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_encoded_data = encoded_data[index]\n",
    "print(sample_encoded_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample_encoded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.35\n",
    "binary_arrays = (sample_encoded_data >= threshold).astype(int)\n",
    "print(binary_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "colors = plt.cm.get_cmap('tab20', len(binary_arrays))\n",
    "\n",
    "for i, binary_array in enumerate(binary_arrays):\n",
    "    x, y, z = np.where(binary_array == 1)\n",
    "    ax.scatter(x, y, z, c=colors(i), marker='o', s=20, label=f'Channel {i + 1}')\n",
    "\n",
    "ax.set_box_aspect([1, 1, 1])\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
